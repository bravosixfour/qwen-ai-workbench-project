# NVIDIA AI Workbench + DGX Spark Setup Guide

**Complete setup for Mac Studio ‚Üí DGX Spark ‚Üí HPC Lab workflow**

## üçé **Step 1: Install AI Workbench on Mac Studio**

### **Prerequisites:**
- **macOS:** 13 (Ventura) or higher
- **CPU:** x86_64 or ARM64 (your M2 Ultra is perfect)
- **RAM:** 16+ GB (you have 128GB, excellent)
- **Storage:** 30-40 GB for containers

### **Installation:**

1. **Download AI Workbench:**
   ```bash
   # Visit: https://www.nvidia.com/en-us/deep-learning-ai/solutions/data-science/workbench/
   # Download the .dmg file for macOS
   ```

2. **Install:**
   ```bash
   # Open the downloaded .dmg file
   # Drag AI Workbench to Applications folder
   # Open from Applications
   ```

3. **Initial Setup:**
   - Launch AI Workbench
   - Complete onboarding wizard
   - Choose Docker as container runtime
   - Configure your preferences

## ‚ö° **Step 2: Install NVIDIA Sync for DGX Spark**

### **Download and Install:**

1. **Get NVIDIA Sync:**
   ```bash
   # Visit: https://build.nvidia.com/spark/connect-to-your-spark/sync
   # Download NVIDIA Sync for macOS
   # Open nvidia-sync.dmg
   # Drag NVIDIA Sync to Applications folder
   ```

2. **Configure DGX Spark Connection:**
   - **Name:** `DGX-Spark-Lab`
   - **Hostname:** `dgx-spark.lab` (or your DGX Spark IP)
   - **Username:** Your DGX Spark username
   - **Password:** Your DGX Spark password (for initial setup only)

3. **NVIDIA Sync will automatically:**
   - Generate SSH key pair
   - Configure passwordless SSH access
   - Create SSH alias for easy connection

4. **Test Connection:**
   ```bash
   # This should work without password prompt
   ssh dgx-spark.lab
   ```

## üõ†Ô∏è **Step 3: Configure AI Workbench for Remote Development**

### **Add DGX Spark as Remote Location:**

1. **Open AI Workbench Desktop**
2. **Go to Settings ‚Üí Locations**
3. **Add Remote Location:**
   - **Name:** `DGX Spark Lab`
   - **Type:** Remote
   - **Host:** `dgx-spark.lab`
   - **Username:** Your username
   - **SSH Key:** Use the key generated by NVIDIA Sync
   - **Port:** 22

### **Test Remote Connection:**
- Connection should show green/active status
- You should be able to browse remote filesystem

## üöÄ **Step 4: Setup Our Qwen Project in AI Workbench**

### **Import Project:**

1. **From AI Workbench Desktop:**
   - Click "Open Project"
   - Navigate to: `/Users/thahirkareem/labnet/qwen-ai-workbench-project`
   - AI Workbench will recognize the `.project/spec.yaml`

2. **Project Configuration:**
   - **Name:** `Qwen Image Edit Lab`
   - **Description:** Multi-server AI image editing deployment
   - **Base Image:** NVIDIA PyTorch container
   - **GPU Required:** Yes

### **Environment Setup:**

The project includes three pre-configured environments:

#### **1. Local Development (Mac):**
```yaml
- Local testing and development
- No GPU required (CPU fallback)
- Perfect for UI development and testing
```

#### **2. DGX Spark Environment:**
```yaml
- Remote development on DGX Spark
- GPU-accelerated testing
- Model validation and optimization
```

#### **3. HPC Production Environment:**
```yaml
- Full HPC cluster deployment
- Maximum performance across all systems
- Production-ready scaling
```

## üéÆ **Step 5: Complete Workflow Configuration**

### **Mac Development Workflow:**

```bash
# 1. Open project in AI Workbench
# 2. Start local development environment
nvwb start --environment local

# 3. Develop and test locally
code .  # VS Code integration

# 4. Deploy to DGX Spark for GPU testing
nvwb deploy --target dgx-spark --environment dgx-spark

# 5. Scale to HPC lab when ready
./startup-scripts/mac-orchestrator.sh deploy
```

### **DGX Spark Integration:**

1. **Development on Spark:**
   - Use AI Workbench to connect to DGX Spark
   - Develop with full GPU acceleration
   - Test models with enterprise-grade hardware

2. **AI Workbench Features on DGX Spark:**
   - JupyterLab with GPU support
   - VS Code remote development
   - Integrated Git workflow
   - Model versioning and tracking

## üìä **Step 6: Advanced Configuration**

### **Multi-Location Deployment:**

```bash
# Configure multiple deployment targets
nvwb config add-location --name hpc-1 --host hpc-1.lab
nvwb config add-location --name hpc-2 --host hpc-2.lab  
nvwb config add-location --name hpc-3 --host hpc-3.lab
```

### **GPU Resource Management:**

```yaml
# AI Workbench automatically detects and manages:
- DGX Spark GPUs (H100/latest architecture)
- HPC-1: 2x RTX PRO 6000 Blackwell (192GB VRAM)
- HPC-2: 3x RTX 5090 (96GB VRAM)
- HPC-3: 1x L40 (48GB VRAM)
```

### **Intelligent Workload Distribution:**

AI Workbench + our orchestrator provides:

1. **Development:** Mac ‚Üí DGX Spark (interactive)
2. **Testing:** DGX Spark ‚Üí HPC-3 (validation)
3. **Production:** DGX Spark ‚Üí HPC-1 (maximum performance)
4. **Scale:** All systems for peak workloads

## üåê **Step 7: Unified Access Dashboard**

### **AI Workbench Integration:**

Once configured, you'll have:

```bash
# Single interface for all systems
AI Workbench Dashboard:
‚îú‚îÄ‚îÄ Local (Mac Studio) - Development
‚îú‚îÄ‚îÄ DGX Spark - Testing & Orchestration  
‚îú‚îÄ‚îÄ HPC-1 - Production (192GB VRAM)
‚îú‚îÄ‚îÄ HPC-2 - Multi-User (3x RTX 5090)
‚îî‚îÄ‚îÄ HPC-3 - Development (L40)
```

### **Access URLs:**

```bash
# AI Workbench will provide unified access to:
Local Development:   http://localhost:8888 (JupyterLab)
DGX Spark:          http://dgx-spark.lab:8888
HPC Production:     http://hpc-1.lab:8001 (via orchestrator)
Multi-User:         http://hpc-2.lab:8002 (via orchestrator)
Development:        http://hpc-3.lab:8003 (via orchestrator)
```

## üéØ **Daily Workflow Examples**

### **Morning Development Session:**
```bash
# 1. Check all systems from AI Workbench dashboard
# 2. Start development environment on DGX Spark
nvwb start --target dgx-spark --environment dgx-spark

# 3. Open JupyterLab or VS Code remotely
# 4. Develop and test with full GPU acceleration
# 5. Commit changes via integrated Git
```

### **Afternoon Production Deployment:**
```bash
# 1. Validate on DGX Spark
nvwb test --target dgx-spark

# 2. Deploy to production via orchestrator
./startup-scripts/mac-orchestrator.sh deploy

# 3. Monitor via unified dashboard
./startup-scripts/mac-orchestrator.sh dashboard
```

## üí° **Key Benefits of This Setup**

### **Enterprise Integration:**
- **NVIDIA Native:** Full NVIDIA stack integration
- **Enterprise Support:** DGX Spark comes with enterprise support
- **Optimized Software:** Pre-tuned AI software stack
- **Future-Proof:** Ready for latest NVIDIA technologies

### **Seamless Development:**
- **Mac Native:** Familiar macOS development environment
- **One-Click Deploy:** From Mac to any system in your lab
- **Unified Monitoring:** Single dashboard for all systems
- **Automatic Scaling:** Intelligent workload distribution

### **Cost Efficiency:**
- **Local Development:** Save GPU time for when you need it
- **Smart Routing:** Use appropriate system for each task  
- **Resource Optimization:** Maximize utilization across lab
- **Enterprise Alternative:** Avoid cloud costs with on-premises power

## üîß **Troubleshooting**

### **Common Issues:**

1. **SSH Connection Failed:**
   ```bash
   # Regenerate SSH keys via NVIDIA Sync
   # Verify network connectivity: ping dgx-spark.lab
   # Check SSH service: ssh -v dgx-spark.lab
   ```

2. **GPU Not Detected:**
   ```bash
   # Verify GPU drivers on target system
   ssh dgx-spark.lab "nvidia-smi"
   # Check AI Workbench GPU settings
   ```

3. **Container Build Failed:**
   ```bash
   # Check Docker/Podman installation
   # Verify container registry access
   # Review build logs in AI Workbench
   ```

## üéâ **Next Steps**

1. **Install AI Workbench + NVIDIA Sync on Mac**
2. **Connect to your DGX Spark**
3. **Import our Qwen project**
4. **Test the complete workflow**
5. **Scale to your HPC lab**

You now have a **world-class AI development infrastructure** that rivals any enterprise setup! üöÄ